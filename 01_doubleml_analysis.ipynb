{
 "cells": [
  {
   "cell_type": "markdown",
   "source": "# DoubleML Analysis: Water Treatment Impact on E.coli Risk\n\nThis notebook implements comprehensive Double Machine Learning analysis with:\n- Base models (PLR & IRM) with specified covariates\n- Extended models (PLR & IRM) with all covariates\n- Subsample analysis by RiskSource categories\n- **Multi-learner comparison** (Lasso, CART, Random Forest, XGBoost, and mixed combinations)\n- LaTeX table outputs for each analysis\n\n**Note**: This notebook is self-contained - it loads raw data and performs all preprocessing internally.\n\n## Analysis Structure:\n1. **Data Loading & Preprocessing** - Load raw MICS data and apply transformations\n2. **Helper Functions** - Define DML model runners and table formatters\n3. **SomeRiskHome Analysis** - Base, Extended, and Subsample models\n4. **VeryHighRiskHome Analysis** - Base, Extended, and Subsample models\n5. **Multi-Learner Comparison** - Robustness checks across ML algorithms (following Ahrens et al., 2024)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### 5.5 Key Findings from Multi-Learner Comparison",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Create RMSE comparison table\ndef create_rmse_table(plr_results, irm_results, outcome_name):\n    \"\"\"Create table comparing RMSE across learners.\"\"\"\n    \n    rows = []\n    learners = list(plr_results.keys())\n    \n    for learner in learners:\n        plr = plr_results.get(learner)\n        irm = irm_results.get(learner)\n        \n        row = {'Learner': learner}\n        \n        if plr is not None:\n            row['PLR RMSE$_l$'] = f\"{plr['rmse_l']:.4f}\" if not np.isnan(plr['rmse_l']) else '-'\n            row['PLR RMSE$_m$'] = f\"{plr['rmse_m']:.4f}\" if not np.isnan(plr['rmse_m']) else '-'\n        else:\n            row['PLR RMSE$_l$'] = '-'\n            row['PLR RMSE$_m$'] = '-'\n            \n        if irm is not None:\n            row['IRM RMSE$_g$'] = f\"{irm['rmse_l']:.4f}\" if not np.isnan(irm['rmse_l']) else '-'\n            row['IRM RMSE$_m$'] = f\"{irm['rmse_m']:.4f}\" if not np.isnan(irm['rmse_m']) else '-'\n        else:\n            row['IRM RMSE$_g$'] = '-'\n            row['IRM RMSE$_m$'] = '-'\n        \n        rows.append(row)\n    \n    df = pd.DataFrame(rows)\n    \n    print(f\"\\n{'='*80}\")\n    print(f\"RMSE Comparison: {outcome_name}\".center(80))\n    print(f\"{'='*80}\")\n    print(df.to_string(index=False))\n    print(f\"{'='*80}\")\n    print(\"RMSE$_l$/RMSE$_g$ = outcome model; RMSE$_m$ = treatment/propensity model\")\n    print(\"Lower RMSE indicates better nuisance model fit.\\n\")\n    \n    return df\n\n# RMSE tables for both outcomes\nrmse_somerisk = create_rmse_table(somerisk_plr_learners, somerisk_irm_learners, \"SomeRiskHome\")\nrmse_veryhigh = create_rmse_table(veryhigh_plr_learners, veryhigh_irm_learners, \"VeryHighRiskHome\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### 5.4 RMSE Comparison Across Learners\n\nThis section compares nuisance model performance (RMSE) across learners, which helps assess whether treatment effect estimates are sensitive to learner choice.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Create LaTeX version of paper-style table\ndef create_latex_paper_table(somerisk_plr, somerisk_irm, veryhigh_plr, veryhigh_irm, n_controls):\n    \"\"\"Generate LaTeX code for the multi-learner comparison table.\"\"\"\n    \n    learners = list(somerisk_plr.keys())\n    \n    latex_lines = [\n        r\"\\begin{table}[htbp]\",\n        r\"\\centering\",\n        r\"\\caption{Multi-Learner DML Comparison: Effect of Water Treatment on E.coli Risk}\",\n        r\"\\label{tab:multi_learner_comparison}\",\n        r\"\\small\",\n        r\"\\begin{tabular}{l cccc cccc}\",\n        r\"\\toprule\",\n        r\"& \\multicolumn{4}{c}{SomeRiskHome} & \\multicolumn{4}{c}{VeryHighRiskHome} \\\\\",\n        r\"\\cmidrule(lr){2-5} \\cmidrule(lr){6-9}\",\n        r\"Learner & PLR & SE & IRM & SE & PLR & SE & IRM & SE \\\\\",\n        r\"\\midrule\",\n    ]\n    \n    for learner in learners:\n        sr_plr = somerisk_plr.get(learner)\n        sr_irm = somerisk_irm.get(learner)\n        vh_plr = veryhigh_plr.get(learner)\n        vh_irm = veryhigh_irm.get(learner)\n        \n        def fmt_coef_latex(result):\n            if result is None:\n                return '-', '-'\n            pval = result['pval']\n            sig = '^{***}' if pval < 0.01 else ('^{**}' if pval < 0.05 else ('^{*}' if pval < 0.10 else ''))\n            return f\"${result['coef']:.4f}{sig}$\", f\"({result['se']:.4f})\"\n        \n        sr_plr_coef, sr_plr_se = fmt_coef_latex(sr_plr)\n        sr_irm_coef, sr_irm_se = fmt_coef_latex(sr_irm)\n        vh_plr_coef, vh_plr_se = fmt_coef_latex(vh_plr)\n        vh_irm_coef, vh_irm_se = fmt_coef_latex(vh_irm)\n        \n        # Escape special characters in learner name\n        learner_escaped = learner.replace('+', r'\\texttt{+}').replace('_', r'\\_')\n        \n        latex_lines.append(\n            f\"{learner_escaped} & {sr_plr_coef} & {sr_plr_se} & {sr_irm_coef} & {sr_irm_se} & \"\n            f\"{vh_plr_coef} & {vh_plr_se} & {vh_irm_coef} & {vh_irm_se} \\\\\\\\\"\n        )\n    \n    latex_lines.extend([\n        r\"\\midrule\",\n        f\"No. of controls & \\\\multicolumn{{8}}{{c}}{{{n_controls}}} \\\\\\\\\",\n        f\"N observations & \\\\multicolumn{{8}}{{c}}{{{somerisk_plr[list(somerisk_plr.keys())[0]]['n_obs']:,}}} \\\\\\\\\",\n        r\"\\bottomrule\",\n        r\"\\end{tabular}\",\n        r\"\\begin{tablenotes}\",\n        r\"\\small\",\n        r\"\\item Note: $^{***}$ p$<$0.01, $^{**}$ p$<$0.05, $^{*}$ p$<$0.10. Standard errors in parentheses.\",\n        r\"\\item PLR = Partially Linear Regression, IRM = Interactive Regression Model.\",\n        r\"\\item All models use 5-fold cross-fitting with consistent sample splits across learners.\",\n        r\"\\item Mixed learners (e.g., Lasso + RF) use different algorithms for outcome (ml\\_l/ml\\_g) vs. treatment (ml\\_m) models.\",\n        r\"\\end{tablenotes}\",\n        r\"\\end{table}\",\n    ])\n    \n    return \"\\n\".join(latex_lines)\n\n# Generate and save LaTeX table\nlatex_paper_table = create_latex_paper_table(\n    somerisk_plr_learners, \n    somerisk_irm_learners,\n    veryhigh_plr_learners, \n    veryhigh_irm_learners,\n    n_controls=len(extended_covariates)\n)\n\nwith open('tables/multi_learner_comparison.tex', 'w') as f:\n    f.write(latex_paper_table)\n\nprint(\"LaTeX table saved to tables/multi_learner_comparison.tex\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "def create_paper_style_table(somerisk_plr, somerisk_irm, veryhigh_plr, veryhigh_irm, n_controls):\n    \"\"\"\n    Create a paper-style comparison table with all learners and both outcomes.\n    Format similar to the reference table from IZA Discussion Paper.\n    \"\"\"\n    \n    learners = list(somerisk_plr.keys())\n    \n    # Build table data\n    table_data = []\n    \n    for learner in learners:\n        sr_plr = somerisk_plr.get(learner)\n        sr_irm = somerisk_irm.get(learner)\n        vh_plr = veryhigh_plr.get(learner)\n        vh_irm = veryhigh_irm.get(learner)\n        \n        # Helper function for formatting\n        def fmt_coef(result):\n            if result is None:\n                return '-', '-'\n            pval = result['pval']\n            sig = '***' if pval < 0.01 else ('**' if pval < 0.05 else ('*' if pval < 0.10 else ''))\n            return f\"{result['coef']:.4f}{sig}\", f\"({result['se']:.4f})\"\n        \n        def fmt_rmse(result, key='rmse_l'):\n            if result is None:\n                return '-'\n            val = result.get(key, np.nan)\n            return f\"{val:.4f}\" if not np.isnan(val) else '-'\n        \n        sr_plr_coef, sr_plr_se = fmt_coef(sr_plr)\n        sr_irm_coef, sr_irm_se = fmt_coef(sr_irm)\n        vh_plr_coef, vh_plr_se = fmt_coef(vh_plr)\n        vh_irm_coef, vh_irm_se = fmt_coef(vh_irm)\n        \n        table_data.append({\n            'Learner': learner,\n            'SomeRisk PLR': sr_plr_coef,\n            'SE': sr_plr_se,\n            'SomeRisk IRM': sr_irm_coef,\n            'SE.1': sr_irm_se,\n            'VeryHigh PLR': vh_plr_coef,\n            'SE.2': vh_plr_se,\n            'VeryHigh IRM': vh_irm_coef,\n            'SE.3': vh_irm_se,\n        })\n    \n    df = pd.DataFrame(table_data)\n    \n    # Print formatted table\n    print(\"\\n\" + \"=\"*140)\n    print(\"MULTI-LEARNER DML COMPARISON: Effect of Water Treatment on E.coli Risk\".center(140))\n    print(\"=\"*140)\n    print(f\"{'Dependent Variable:':^20} {'SomeRiskHome':^55} {'VeryHighRiskHome':^55}\")\n    print(f\"{'':^20} {'PLR':^27} {'IRM':^27} {'PLR':^27} {'IRM':^27}\")\n    print(\"-\"*140)\n    \n    for _, row in df.iterrows():\n        print(f\"{row['Learner']:^20} {row['SomeRisk PLR']:^13} {row['SE']:^13} \"\n              f\"{row['SomeRisk IRM']:^13} {row['SE.1']:^13} \"\n              f\"{row['VeryHigh PLR']:^13} {row['SE.2']:^13} \"\n              f\"{row['VeryHigh IRM']:^13} {row['SE.3']:^13}\")\n    \n    print(\"-\"*140)\n    print(f\"No. of controls: {n_controls}\")\n    print(f\"N observations: {somerisk_plr[list(somerisk_plr.keys())[0]]['n_obs']:,}\")\n    print(\"=\"*140)\n    print(\"Note: *** p<0.01, ** p<0.05, * p<0.10\")\n    print(\"Standard errors in parentheses. All models use 5-fold cross-fitting with consistent sample splits.\")\n    print()\n    \n    return df\n\n# Create paper-style summary table\npaper_table = create_paper_style_table(\n    somerisk_plr_learners, \n    somerisk_irm_learners,\n    veryhigh_plr_learners, \n    veryhigh_irm_learners,\n    n_controls=len(extended_covariates)\n)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### 5.3 Summary Comparison Table (Paper-Style Format)\n\nThis table presents results in a format similar to Table 2 in Ahrens et al. (2024), showing treatment effects across multiple ML learners for both outcome variables.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Create combined comparison table for VeryHighRiskHome\nveryhigh_combined_table = create_combined_comparison_table(\n    veryhigh_plr_learners, \n    veryhigh_irm_learners,\n    \"Multi-Learner Comparison: VeryHighRiskHome (Extended Controls)\"\n)\n\n# Export to LaTeX\nlatex_veryhigh_learners = veryhigh_combined_table.to_latex(\n    index=False, \n    caption=\"Multi-Learner Comparison for VeryHighRiskHome (Extended Controls). PLR = Partially Linear Regression, IRM = Interactive Regression Model. RMSE values are cross-validated nuisance model losses.\",\n    label=\"tab:veryhigh_learner_comparison\",\n    escape=False\n)\n\nwith open('tables/veryhigh_learner_comparison.tex', 'w') as f:\n    f.write(latex_veryhigh_learners)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Run multi-learner comparison for VeryHighRiskHome with extended controls\nprint(\"Running PLR models with multiple learners...\")\nveryhigh_plr_learners = run_multi_learner_comparison(\n    data_complete, 'VeryHighRiskHome', extended_covariates, 'plr'\n)\n\nprint(\"\\nRunning IRM models with multiple learners...\")\nveryhigh_irm_learners = run_multi_learner_comparison(\n    data_complete, 'VeryHighRiskHome', extended_covariates, 'irm'\n)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### 5.2 Multi-Learner Comparison: VeryHighRiskHome (Extended Controls)",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Create combined comparison table for SomeRiskHome\nsomerisk_combined_table = create_combined_comparison_table(\n    somerisk_plr_learners, \n    somerisk_irm_learners,\n    \"Multi-Learner Comparison: SomeRiskHome (Extended Controls)\"\n)\n\n# Export to LaTeX\nlatex_somerisk_learners = somerisk_combined_table.to_latex(\n    index=False, \n    caption=\"Multi-Learner Comparison for SomeRiskHome (Extended Controls). PLR = Partially Linear Regression, IRM = Interactive Regression Model. RMSE values are cross-validated nuisance model losses.\",\n    label=\"tab:somerisk_learner_comparison\",\n    escape=False\n)\n\nwith open('tables/somerisk_learner_comparison.tex', 'w') as f:\n    f.write(latex_somerisk_learners)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Run multi-learner comparison for SomeRiskHome with extended controls\nprint(\"Running PLR models with multiple learners...\")\nsomerisk_plr_learners = run_multi_learner_comparison(\n    data_complete, 'SomeRiskHome', extended_covariates, 'plr'\n)\n\nprint(\"\\nRunning IRM models with multiple learners...\")\nsomerisk_irm_learners = run_multi_learner_comparison(\n    data_complete, 'SomeRiskHome', extended_covariates, 'irm'\n)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### 5.1 Multi-Learner Comparison: SomeRiskHome (Extended Controls)",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "def create_learner_comparison_table(results_dict, title, model_type='plr'):\n    \"\"\"\n    Create formatted comparison table similar to the reference paper style.\n    \n    Parameters:\n    -----------\n    results_dict : dict\n        Dictionary with learner results\n    title : str\n        Table title\n    model_type : str\n        'plr' or 'irm' (affects column naming)\n        \n    Returns:\n    --------\n    DataFrame : Formatted results table\n    \"\"\"\n    rows = []\n    \n    for learner_name, result in results_dict.items():\n        if result is None:\n            continue\n            \n        pval = result['pval']\n        \n        # Format significance stars\n        if pval < 0.01:\n            sig = '***'\n        elif pval < 0.05:\n            sig = '**'\n        elif pval < 0.10:\n            sig = '*'\n        else:\n            sig = ''\n        \n        rows.append({\n            'Learner': learner_name,\n            'Coefficient': f\"{result['coef']:.4f}{sig}\",\n            'Std. Error': f\"({result['se']:.4f})\",\n            '95\\\\% CI': f\"[{result['ci_lower']:.4f}, {result['ci_upper']:.4f}]\",\n            'RMSE$_l$' if model_type == 'plr' else 'RMSE$_g$': f\"{result['rmse_l']:.4f}\" if not np.isnan(result['rmse_l']) else '-',\n            'RMSE$_m$': f\"{result['rmse_m']:.4f}\" if not np.isnan(result['rmse_m']) else '-',\n        })\n    \n    df = pd.DataFrame(rows)\n    \n    print(f\"\\n{'='*100}\")\n    print(f\"{title.center(100)}\")\n    print(f\"{'='*100}\")\n    print(df.to_string(index=False))\n    print(f\"{'='*100}\")\n    print(\"Note: *** p<0.01, ** p<0.05, * p<0.10\")\n    print(f\"RMSE$_l$/RMSE$_g$ = outcome model loss; RMSE$_m$ = treatment/propensity model loss\\n\")\n    \n    return df\n\ndef create_combined_comparison_table(plr_results, irm_results, title):\n    \"\"\"\n    Create a combined table showing both PLR and IRM results side by side.\n    \n    Parameters:\n    -----------\n    plr_results : dict\n        PLR model results\n    irm_results : dict\n        IRM model results\n    title : str\n        Table title\n        \n    Returns:\n    --------\n    DataFrame : Combined results table\n    \"\"\"\n    rows = []\n    \n    learners = list(plr_results.keys())\n    \n    for learner in learners:\n        plr = plr_results.get(learner)\n        irm = irm_results.get(learner)\n        \n        if plr is None and irm is None:\n            continue\n        \n        # PLR results\n        if plr is not None:\n            plr_pval = plr['pval']\n            plr_sig = '***' if plr_pval < 0.01 else ('**' if plr_pval < 0.05 else ('*' if plr_pval < 0.10 else ''))\n            plr_coef = f\"{plr['coef']:.4f}{plr_sig}\"\n            plr_se = f\"({plr['se']:.4f})\"\n            plr_rmse_l = f\"{plr['rmse_l']:.4f}\" if not np.isnan(plr['rmse_l']) else '-'\n            plr_rmse_m = f\"{plr['rmse_m']:.4f}\" if not np.isnan(plr['rmse_m']) else '-'\n        else:\n            plr_coef = plr_se = plr_rmse_l = plr_rmse_m = '-'\n        \n        # IRM results\n        if irm is not None:\n            irm_pval = irm['pval']\n            irm_sig = '***' if irm_pval < 0.01 else ('**' if irm_pval < 0.05 else ('*' if irm_pval < 0.10 else ''))\n            irm_coef = f\"{irm['coef']:.4f}{irm_sig}\"\n            irm_se = f\"({irm['se']:.4f})\"\n            irm_rmse_g = f\"{irm['rmse_l']:.4f}\" if not np.isnan(irm['rmse_l']) else '-'\n            irm_rmse_m = f\"{irm['rmse_m']:.4f}\" if not np.isnan(irm['rmse_m']) else '-'\n        else:\n            irm_coef = irm_se = irm_rmse_g = irm_rmse_m = '-'\n        \n        rows.append({\n            'Learner': learner,\n            'PLR Coef.': plr_coef,\n            'PLR SE': plr_se,\n            'PLR RMSE$_l$': plr_rmse_l,\n            'PLR RMSE$_m$': plr_rmse_m,\n            'IRM Coef.': irm_coef,\n            'IRM SE': irm_se,\n            'IRM RMSE$_g$': irm_rmse_g,\n            'IRM RMSE$_m$': irm_rmse_m,\n        })\n    \n    df = pd.DataFrame(rows)\n    \n    print(f\"\\n{'='*120}\")\n    print(f\"{title.center(120)}\")\n    print(f\"{'='*120}\")\n    print(df.to_string(index=False))\n    print(f\"{'='*120}\")\n    print(\"Note: *** p<0.01, ** p<0.05, * p<0.10\")\n    print(\"RMSE$_l$/RMSE$_g$ = outcome model loss; RMSE$_m$ = treatment/propensity model loss\\n\")\n    \n    return df\n\nprint(\"Table creation functions defined.\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "def run_multi_learner_comparison(data, outcome, covariates, model_type='plr'):\n    \"\"\"\n    Run DML with multiple learners using consistent sample splitting.\n    \n    Parameters:\n    -----------\n    data : DataFrame\n        Complete dataset\n    outcome : str\n        Outcome variable name\n    covariates : list\n        List of covariate names\n    model_type : str\n        'plr' or 'irm'\n        \n    Returns:\n    --------\n    dict : Results for all learner configurations\n    \"\"\"\n    \n    # Create DoubleML data object\n    dml_data = DoubleMLData(\n        data=data,\n        y_col=outcome,\n        d_cols=treatment_var,\n        x_cols=covariates\n    )\n    \n    # Get learner configurations\n    configs = get_learner_configs()\n    \n    # Initialize first model to get sample splitting\n    first_config = list(configs.values())[0]\n    if model_type == 'plr':\n        first_model = DoubleMLPLR(\n            dml_data, \n            ml_l=copy.deepcopy(first_config['ml_l']), \n            ml_m=copy.deepcopy(first_config['ml_m']),\n            n_folds=5,\n            draw_sample_splitting=True\n        )\n    else:\n        first_model = DoubleMLIRM(\n            dml_data, \n            ml_g=copy.deepcopy(first_config['ml_g']), \n            ml_m=copy.deepcopy(first_config['ml_m']),\n            n_folds=5,\n            draw_sample_splitting=True\n        )\n    \n    # Store sample splitting for reuse\n    smpls = first_model.smpls\n    \n    results = {}\n    \n    for learner_name, config in configs.items():\n        print(f\"  Running {learner_name}...\", end=\" \")\n        \n        try:\n            if model_type == 'plr':\n                model = DoubleMLPLR(\n                    dml_data, \n                    ml_l=copy.deepcopy(config['ml_l']), \n                    ml_m=copy.deepcopy(config['ml_m']),\n                    n_folds=5,\n                    draw_sample_splitting=False\n                )\n            else:\n                model = DoubleMLIRM(\n                    dml_data, \n                    ml_g=copy.deepcopy(config['ml_g']), \n                    ml_m=copy.deepcopy(config['ml_m']),\n                    n_folds=5,\n                    draw_sample_splitting=False\n                )\n            \n            # Use same sample splitting\n            model.set_sample_splitting(smpls)\n            \n            # Fit model\n            model.fit()\n            \n            # Extract nuisance losses (RMSE)\n            nuisance_loss = model.nuisance_loss\n            \n            # Get RMSE for outcome and treatment models\n            if model_type == 'plr':\n                rmse_l = np.sqrt(np.mean(nuisance_loss['ml_l'])) if 'ml_l' in nuisance_loss else np.nan\n                rmse_m = np.sqrt(np.mean(nuisance_loss['ml_m'])) if 'ml_m' in nuisance_loss else np.nan\n            else:\n                rmse_l = np.sqrt(np.mean(nuisance_loss['ml_g'])) if 'ml_g' in nuisance_loss else np.nan\n                rmse_m = np.sqrt(np.mean(nuisance_loss['ml_m'])) if 'ml_m' in nuisance_loss else np.nan\n            \n            results[learner_name] = {\n                'model': model,\n                'coef': model.coef[0],\n                'se': model.se[0],\n                'ci_lower': model.confint()['2.5 %'].values[0],\n                'ci_upper': model.confint()['97.5 %'].values[0],\n                'pval': model.pval[0],\n                'rmse_l': rmse_l,\n                'rmse_m': rmse_m,\n                'n_obs': len(data)\n            }\n            print(\"Done\")\n            \n        except Exception as e:\n            print(f\"Error: {str(e)[:50]}\")\n            results[learner_name] = None\n    \n    return results\n\nprint(\"Multi-learner comparison function defined.\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Additional imports for multi-learner comparison\nfrom sklearn.linear_model import LogisticRegressionCV, LassoCV\nfrom sklearn.ensemble import RandomForestClassifier, RandomForestRegressor, GradientBoostingClassifier\nfrom sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\nfrom doubleml import DoubleMLPLR, DoubleMLIRM\nimport copy\n\n# Define learner configurations\n# For binary outcomes, we use classifiers; for propensity score (treatment), we use classifiers\ndef get_learner_configs():\n    \"\"\"\n    Define learner configurations for DML comparison.\n    \n    For PLR with binary outcome:\n    - ml_l: predicts E[Y|X] (outcome model) - use classifier for binary Y\n    - ml_m: predicts E[D|X] (propensity score) - use classifier for binary D\n    \n    For IRM:\n    - ml_g: predicts E[Y|X,D] (outcome model) - use classifier for binary Y\n    - ml_m: predicts E[D|X] (propensity score) - use classifier for binary D\n    \"\"\"\n    \n    configs = {\n        # Single learner configurations (same learner for both nuisance functions)\n        'Lasso': {\n            'ml_l': LogisticRegressionCV(cv=5, penalty='l1', solver='saga', max_iter=1000, random_state=42),\n            'ml_m': LogisticRegressionCV(cv=5, penalty='l1', solver='saga', max_iter=1000, random_state=42),\n            'ml_g': LogisticRegressionCV(cv=5, penalty='l1', solver='saga', max_iter=1000, random_state=42),\n        },\n        'CART': {\n            'ml_l': DecisionTreeClassifier(max_depth=10, min_samples_leaf=20, random_state=42),\n            'ml_m': DecisionTreeClassifier(max_depth=10, min_samples_leaf=20, random_state=42),\n            'ml_g': DecisionTreeClassifier(max_depth=10, min_samples_leaf=20, random_state=42),\n        },\n        'Random Forest': {\n            'ml_l': RandomForestClassifier(n_estimators=100, max_depth=10, min_samples_leaf=20, \n                                           n_jobs=-1, random_state=42),\n            'ml_m': RandomForestClassifier(n_estimators=100, max_depth=10, min_samples_leaf=20,\n                                           n_jobs=-1, random_state=42),\n            'ml_g': RandomForestClassifier(n_estimators=100, max_depth=10, min_samples_leaf=20,\n                                           n_jobs=-1, random_state=42),\n        },\n        'XGBoost': {\n            'ml_l': XGBClassifier(n_estimators=100, max_depth=5, learning_rate=0.1, \n                                  eval_metric='logloss', random_state=42),\n            'ml_m': XGBClassifier(n_estimators=100, max_depth=5, learning_rate=0.1,\n                                  eval_metric='logloss', random_state=42),\n            'ml_g': XGBClassifier(n_estimators=100, max_depth=5, learning_rate=0.1,\n                                  eval_metric='logloss', random_state=42),\n        },\n        # Mixed learner configurations (different learners for outcome vs treatment)\n        'Lasso + RF': {\n            'ml_l': LogisticRegressionCV(cv=5, penalty='l1', solver='saga', max_iter=1000, random_state=42),\n            'ml_m': RandomForestClassifier(n_estimators=100, max_depth=10, min_samples_leaf=20,\n                                           n_jobs=-1, random_state=42),\n            'ml_g': LogisticRegressionCV(cv=5, penalty='l1', solver='saga', max_iter=1000, random_state=42),\n        },\n        'RF + XGBoost': {\n            'ml_l': RandomForestClassifier(n_estimators=100, max_depth=10, min_samples_leaf=20,\n                                           n_jobs=-1, random_state=42),\n            'ml_m': XGBClassifier(n_estimators=100, max_depth=5, learning_rate=0.1,\n                                  eval_metric='logloss', random_state=42),\n            'ml_g': RandomForestClassifier(n_estimators=100, max_depth=10, min_samples_leaf=20,\n                                           n_jobs=-1, random_state=42),\n        },\n    }\n    \n    return configs\n\nprint(\"Learner configurations defined.\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DoubleML Analysis: Water Treatment Impact on E.coli Risk\n",
    "\n",
    "This notebook implements comprehensive Double Machine Learning analysis with:\n",
    "- Base models (PLR & IRM) with specified covariates\n",
    "- Extended models (PLR & IRM) with all covariates\n",
    "- Subsample analysis by RiskSource categories\n",
    "- LaTeX table outputs for each analysis\n",
    "\n",
    "**Note**: This notebook is self-contained - it loads raw data and performs all preprocessing internally."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable Definitions\n",
    "\n",
    "| Variable | Role | Type | Description |\n",
    "|----------|------|------|-------------|\n",
    "| **Outcome Variables (Y)** ||||\n",
    "| `SomeRiskHome` | Dependent | Binary | E.coli risk indicator (1 = some risk, 0 = no risk) |\n",
    "| `VeryHighRiskHome` | Dependent | Binary | High E.coli risk indicator (1 = very high risk, 0 = otherwise) |\n",
    "| **Treatment Variable (T)** ||||\n",
    "| `water_treatment` | Treatment | Binary | Household treats water before drinking (1 = yes, 0 = no) |\n",
    "| **Subsample Variable** ||||\n",
    "| `RiskSource` | Stratification | Categorical | Water source risk level: \"No risk\", \"Moderate to high risk\", \"Very high risk\" |\n",
    "| **Basic Controls** ||||\n",
    "| `windex5` | Control | Ordinal (0-4) | Wealth index quintile (0=Poorest, 1=Poor, 2=Middle, 3=Rich, 4=Richest) |\n",
    "| `helevel` | Control | Ordinal (0-2) | Education level (0=None, 1=Primary, 2=Secondary+) |\n",
    "| `urban` | Control | Binary | Urban residence (1=Urban, 0=Rural) |\n",
    "| `wq27_decile` | Control | Ordinal (1-10) | Water quality decile based on E.coli contamination |\n",
    "| `country_cat_*` | Control | Binary (one-hot) | Country fixed effects (24 countries, reference: Bangladesh) |\n",
    "| `WS1_g_*` | Control | Binary (one-hot) | Water source type groups (7 types, reference: Delivered water) |\n",
    "| **Extended Controls - Household Composition** ||||\n",
    "| `Any_U5` | Control | Binary | Household has children under 5 years |\n",
    "| `Girls_less_than15` | Control | Binary | Household has girls under 15 years |\n",
    "| `Boys_15or_less` | Control | Binary | Household has boys 15 years or younger |\n",
    "| **Extended Controls - Sanitation** ||||\n",
    "| `improved_latrine` | Control | Binary | Household has improved latrine facility |\n",
    "| `Flush` | Control | Binary | Household has flush toilet |\n",
    "| `Pit_latrine` | Control | Binary | Household uses pit latrine |\n",
    "| `Open_defecation` | Control | Binary | Household practices open defecation |\n",
    "| **Extended Controls - Water Sources & Services** ||||\n",
    "| `rainy_season` | Control | Binary | Survey conducted during rainy season |\n",
    "| `RainandSurfaceWater` | Control | Binary | Main water source is rain/surface water |\n",
    "| `PurchasedWater` | Control | Binary | Household purchases water |\n",
    "| `Basic_water_service` | Control | Binary | Household has basic water service level |\n",
    "| `Limited_water_service` | Control | Binary | Household has limited water service level |\n",
    "| `Unimproved_water_service` | Control | Binary | Household has unimproved water service |\n",
    "| `ImprovedWaterSource` | Control | Binary | Water source is classified as improved |\n",
    "| `PipedWater` | Control | Binary | Household has piped water access |\n",
    "| `WellandSpringWater` | Control | Binary | Main water source is well/spring |\n",
    "| `water_carrier_edu` | Control | Ordinal | Education level of person who fetches water (-1=missing/NA) |\n",
    "\n",
    "**Notes:**\n",
    "- **Base model** uses: `windex5`, `helevel`, `country_cat_*`, `WS1_g_*`\n",
    "- **Extended model** uses: All controls listed above\n",
    "- **Subsample analysis** stratifies by `RiskSource` categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import optuna\n",
    "from doubleml import DoubleMLData, DoubleMLPLR, DoubleMLIRM\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Raw Data and Create Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw dataset shape: (56721, 785)\n"
     ]
    }
   ],
   "source": [
    "# Load raw data\n",
    "mics = pd.read_csv(\"mics.csv\", low_memory=False)\n",
    "print(f\"Raw dataset shape: {mics.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Define Variable Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# OUTCOME VARIABLES (Y)\n",
    "# ============================================================\n",
    "outcome_vars = ['SomeRiskHome', 'VeryHighRiskHome']\n",
    "\n",
    "# ============================================================\n",
    "# TREATMENT VARIABLE (T)\n",
    "# ============================================================\n",
    "treatment_var = 'water_treatment'\n",
    "\n",
    "# ============================================================\n",
    "# SUBSAMPLE VARIABLE\n",
    "# ============================================================\n",
    "subsample_var = 'RiskSource'\n",
    "risk_categories = ['No risk', 'Moderate to high risk', 'Very high risk']\n",
    "\n",
    "# ============================================================\n",
    "# BASIC CONTROLS\n",
    "# ============================================================\n",
    "# Ordinal (integer-encoded preserving order)\n",
    "X_basic_ordinal = ['windex5', 'helevel', 'wq27_decile']\n",
    "\n",
    "# Categorical (one-hot encoded)\n",
    "X_basic_categorical = ['country_cat', 'WS1_g']\n",
    "\n",
    "# Binary\n",
    "X_basic_binary = ['urban']\n",
    "\n",
    "# ============================================================\n",
    "# EXTENDED CONTROLS\n",
    "# ============================================================\n",
    "# Binary - Household composition\n",
    "X_extended_household = ['Any_U5', 'Girls_less_than15', 'Boys_15or_less']\n",
    "\n",
    "# Binary - Sanitation\n",
    "X_extended_sanitation = ['improved_latrine', 'Flush', 'Pit_latrine', 'Open_defecation']\n",
    "\n",
    "# Binary - Season & Water sources\n",
    "X_extended_water = [\n",
    "    'rainy_season', 'RainandSurfaceWater', 'PurchasedWater',\n",
    "    'Basic_water_service', 'Limited_water_service', 'Unimproved_water_service',\n",
    "    'ImprovedWaterSource', 'PipedWater', 'WellandSpringWater'\n",
    "]\n",
    "\n",
    "# Ordinal - Extended\n",
    "X_extended_ordinal = ['water_carrier_edu']\n",
    "\n",
    "# Combine all extended binary variables\n",
    "X_extended_binary = X_extended_household + X_extended_sanitation + X_extended_water"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Apply Variable Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ordinal transformations applied.\n"
     ]
    }
   ],
   "source": [
    "# Create urban variable from HH6 column\n",
    "mics['urban'] = mics['HH6'].str.contains('Urban', case=False, na=False).astype(int)\n",
    "\n",
    "# Define and apply ordinal mappings\n",
    "ordinal_mappings = {\n",
    "    'helevel': {'No education': 0, 'Primary': 1, 'Secondary or higher': 2},\n",
    "    'windex5': {'Poorest': 0, 'Poor': 1, 'Middle': 2, 'Rich': 3, 'Richest': 4},\n",
    "}\n",
    "\n",
    "for col, mapping in ordinal_mappings.items():\n",
    "    if mics[col].dtype == 'object':\n",
    "        mics[col] = mics[col].map(mapping).astype('Int64')\n",
    "\n",
    "# Handle water_carrier_edu (98 = missing -> -1 sentinel)\n",
    "mics['water_carrier_edu'] = mics['water_carrier_edu'].replace(98, -1).astype('Int64')\n",
    "\n",
    "print(\"Ordinal transformations applied.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-hot encoded 30 categorical columns.\n"
     ]
    }
   ],
   "source": [
    "# One-hot encode categorical variables\n",
    "onehot_encoder = OneHotEncoder(sparse_output=False, drop='first')\n",
    "encoded_cats = onehot_encoder.fit_transform(mics[X_basic_categorical])\n",
    "encoded_df = pd.DataFrame(\n",
    "    encoded_cats,\n",
    "    columns=onehot_encoder.get_feature_names_out(X_basic_categorical)\n",
    ")\n",
    "\n",
    "# Concatenate with original data\n",
    "mics = pd.concat([mics.reset_index(drop=True), encoded_df], axis=1)\n",
    "mics.drop(X_basic_categorical, axis=1, inplace=True)\n",
    "\n",
    "# Get encoded column names\n",
    "encoded_cat_cols = list(onehot_encoder.get_feature_names_out(X_basic_categorical))\n",
    "print(f\"One-hot encoded {len(encoded_cat_cols)} categorical columns.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Assemble Final Covariate Lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base covariates: 34 variables\n",
      "Extended covariates: 51 variables\n"
     ]
    }
   ],
   "source": [
    "# Basic controls (for main analysis)\n",
    "base_covariates = (\n",
    "    X_basic_binary +           # urban\n",
    "    X_basic_ordinal +          # windex5, helevel, wq27_decile\n",
    "    encoded_cat_cols           # country_cat_*, WS1_g_*\n",
    ")\n",
    "\n",
    "# Extended controls (basic + additional)\n",
    "extended_covariates = (\n",
    "    X_basic_binary +           # urban\n",
    "    X_basic_ordinal +          # windex5, helevel, wq27_decile\n",
    "    X_extended_binary +        # household, sanitation, water\n",
    "    X_extended_ordinal +       # water_carrier_edu\n",
    "    encoded_cat_cols           # country_cat_*, WS1_g_*\n",
    ")\n",
    "\n",
    "print(f\"Base covariates: {len(base_covariates)} variables\")\n",
    "print(f\"Extended covariates: {len(extended_covariates)} variables\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Prepare Final Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape before dropping NaN: (56721, 55)\n",
      "\n",
      "Missing values:\n",
      "Open_defecation             1209\n",
      "RainandSurfaceWater            3\n",
      "PurchasedWater                 3\n",
      "Basic_water_service            2\n",
      "Limited_water_service          2\n",
      "Unimproved_water_service       3\n",
      "PipedWater                     3\n",
      "WellandSpringWater             3\n",
      "dtype: int64\n",
      "\n",
      "Complete cases: (55510, 55)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SomeRiskHome</th>\n",
       "      <th>VeryHighRiskHome</th>\n",
       "      <th>water_treatment</th>\n",
       "      <th>RiskSource</th>\n",
       "      <th>urban</th>\n",
       "      <th>windex5</th>\n",
       "      <th>helevel</th>\n",
       "      <th>wq27_decile</th>\n",
       "      <th>Any_U5</th>\n",
       "      <th>Girls_less_than15</th>\n",
       "      <th>...</th>\n",
       "      <th>country_cat_Togo</th>\n",
       "      <th>country_cat_Trinidad and Tobago</th>\n",
       "      <th>country_cat_Viet Nam</th>\n",
       "      <th>country_cat_Zimbabwe</th>\n",
       "      <th>WS1_g_Packaged/Bottled water</th>\n",
       "      <th>WS1_g_Piped water</th>\n",
       "      <th>WS1_g_Protected well/spring</th>\n",
       "      <th>WS1_g_Surface/Rain water</th>\n",
       "      <th>WS1_g_Tube/Well/Borehole</th>\n",
       "      <th>WS1_g_Unprotected well/spring</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Moderate to high risk</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No risk</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Very high risk</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Very high risk</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Moderate to high risk</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SomeRiskHome  VeryHighRiskHome  water_treatment             RiskSource  \\\n",
       "0             1                 0                0  Moderate to high risk   \n",
       "1             1                 0                0                No risk   \n",
       "2             1                 1                0         Very high risk   \n",
       "3             1                 1                0         Very high risk   \n",
       "4             1                 0                0  Moderate to high risk   \n",
       "\n",
       "   urban  windex5  helevel  wq27_decile  Any_U5  Girls_less_than15  ...  \\\n",
       "0      0        1        0            7       1                  0  ...   \n",
       "1      0        1        0            1       1                  0  ...   \n",
       "2      0        2        0            8       1                  0  ...   \n",
       "3      0        2        0            8       1                  0  ...   \n",
       "4      0        0        0            8       0                  0  ...   \n",
       "\n",
       "   country_cat_Togo  country_cat_Trinidad and Tobago  country_cat_Viet Nam  \\\n",
       "0               0.0                              0.0                   0.0   \n",
       "1               0.0                              0.0                   0.0   \n",
       "2               0.0                              0.0                   0.0   \n",
       "3               0.0                              0.0                   0.0   \n",
       "4               0.0                              0.0                   0.0   \n",
       "\n",
       "   country_cat_Zimbabwe  WS1_g_Packaged/Bottled water  WS1_g_Piped water  \\\n",
       "0                   0.0                           0.0                0.0   \n",
       "1                   0.0                           0.0                0.0   \n",
       "2                   0.0                           0.0                0.0   \n",
       "3                   0.0                           0.0                0.0   \n",
       "4                   0.0                           0.0                0.0   \n",
       "\n",
       "   WS1_g_Protected well/spring  WS1_g_Surface/Rain water  \\\n",
       "0                          0.0                       0.0   \n",
       "1                          0.0                       0.0   \n",
       "2                          0.0                       0.0   \n",
       "3                          0.0                       0.0   \n",
       "4                          0.0                       0.0   \n",
       "\n",
       "   WS1_g_Tube/Well/Borehole  WS1_g_Unprotected well/spring  \n",
       "0                       1.0                            0.0  \n",
       "1                       1.0                            0.0  \n",
       "2                       1.0                            0.0  \n",
       "3                       0.0                            1.0  \n",
       "4                       1.0                            0.0  \n",
       "\n",
       "[5 rows x 55 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select all relevant columns\n",
    "relevant_cols = outcome_vars + [treatment_var, subsample_var] + extended_covariates\n",
    "data = mics[relevant_cols].copy()\n",
    "\n",
    "print(f\"Dataset shape before dropping NaN: {data.shape}\")\n",
    "print(f\"\\nMissing values:\\n{data.isnull().sum()[data.isnull().sum() > 0]}\")\n",
    "\n",
    "# Drop rows with NaN values (DoubleML requires complete cases)\n",
    "data_complete = data.dropna()\n",
    "print(f\"\\nComplete cases: {data_complete.shape}\")\n",
    "\n",
    "# Display basic info\n",
    "data_complete.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RiskSource value counts:\n",
      "RiskSource\n",
      "No risk                  23323\n",
      "Moderate to high risk    20603\n",
      "Very high risk           11584\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Display RiskSource distribution\n",
    "print(f\"RiskSource value counts:\\n{data_complete['RiskSource'].value_counts()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_hyperparameter_space():\n",
    "    \"\"\"Define hyperparameter search space for XGBoost\"\"\"\n",
    "    return {\n",
    "        'n_estimators': {'low': 50, 'high': 200, 'step': 25},\n",
    "        'max_depth': {'low': 2, 'high': 6},\n",
    "        'min_child_weight': {'low': 1, 'high': 10},\n",
    "        'subsample': {'low': 0.6, 'high': 0.9},\n",
    "        'colsample_bytree': {'low': 0.6, 'high': 0.9},\n",
    "        'learning_rate': {'low': 0.01, 'high': 0.1}\n",
    "    }\n",
    "\n",
    "def run_doubleml_model(data, outcome, covariates, model_type='plr', n_trials=50):\n",
    "    \"\"\"\n",
    "    Run DoubleML model with hyperparameter tuning\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data : DataFrame\n",
    "        Complete dataset\n",
    "    outcome : str\n",
    "        Outcome variable name\n",
    "    covariates : list\n",
    "        List of covariate names\n",
    "    model_type : str\n",
    "        'plr' or 'irm'\n",
    "    n_trials : int\n",
    "        Number of Optuna trials\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict : Model results\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create DoubleML data object\n",
    "    dml_data = DoubleMLData(\n",
    "        data=data,\n",
    "        y_col=outcome,\n",
    "        d_cols=treatment_var,\n",
    "        x_cols=covariates\n",
    "    )\n",
    "    \n",
    "    # Initialize XGBoost classifiers\n",
    "    if model_type == 'plr':\n",
    "        ml_l = XGBClassifier(objective='binary:logistic', eval_metric='logloss', random_state=42)\n",
    "        ml_m = XGBClassifier(objective='binary:logistic', eval_metric='logloss', random_state=42)\n",
    "        model = DoubleMLPLR(dml_data, ml_l=ml_l, ml_m=ml_m)\n",
    "        \n",
    "        def ml_l_params(trial):\n",
    "            hp = create_hyperparameter_space()\n",
    "            return {\n",
    "                'n_estimators': trial.suggest_int('n_estimators', hp['n_estimators']['low'], \n",
    "                                                 hp['n_estimators']['high'], step=hp['n_estimators']['step']),\n",
    "                'max_depth': trial.suggest_int('max_depth', hp['max_depth']['low'], hp['max_depth']['high']),\n",
    "                'min_child_weight': trial.suggest_int('min_child_weight', hp['min_child_weight']['low'], \n",
    "                                                     hp['min_child_weight']['high']),\n",
    "                'subsample': trial.suggest_float('subsample', hp['subsample']['low'], hp['subsample']['high']),\n",
    "                'colsample_bytree': trial.suggest_float('colsample_bytree', hp['colsample_bytree']['low'], \n",
    "                                                        hp['colsample_bytree']['high']),\n",
    "                'learning_rate': trial.suggest_float('learning_rate', hp['learning_rate']['low'], \n",
    "                                                    hp['learning_rate']['high'], log=True)\n",
    "            }\n",
    "        \n",
    "        def ml_m_params(trial):\n",
    "            hp = create_hyperparameter_space()\n",
    "            return {\n",
    "                'n_estimators': trial.suggest_int('n_estimators', hp['n_estimators']['low'], \n",
    "                                                 hp['n_estimators']['high'], step=hp['n_estimators']['step']),\n",
    "                'max_depth': trial.suggest_int('max_depth', hp['max_depth']['low'], hp['max_depth']['high']),\n",
    "                'min_child_weight': trial.suggest_int('min_child_weight', hp['min_child_weight']['low'], \n",
    "                                                     hp['min_child_weight']['high']),\n",
    "                'subsample': trial.suggest_float('subsample', hp['subsample']['low'], hp['subsample']['high']),\n",
    "                'colsample_bytree': trial.suggest_float('colsample_bytree', hp['colsample_bytree']['low'], \n",
    "                                                        hp['colsample_bytree']['high']),\n",
    "                'learning_rate': trial.suggest_float('learning_rate', hp['learning_rate']['low'], \n",
    "                                                    hp['learning_rate']['high'], log=True)\n",
    "            }\n",
    "        \n",
    "        param_space = {'ml_l': ml_l_params, 'ml_m': ml_m_params}\n",
    "        \n",
    "    else:  # IRM\n",
    "        ml_g = XGBClassifier(objective='binary:logistic', eval_metric='logloss', random_state=42)\n",
    "        ml_m = XGBClassifier(objective='binary:logistic', eval_metric='logloss', random_state=42)\n",
    "        model = DoubleMLIRM(dml_data, ml_g=ml_g, ml_m=ml_m)\n",
    "        \n",
    "        def ml_g_params(trial):\n",
    "            hp = create_hyperparameter_space()\n",
    "            return {\n",
    "                'n_estimators': trial.suggest_int('n_estimators', hp['n_estimators']['low'], \n",
    "                                                 hp['n_estimators']['high'], step=hp['n_estimators']['step']),\n",
    "                'max_depth': trial.suggest_int('max_depth', hp['max_depth']['low'], hp['max_depth']['high']),\n",
    "                'min_child_weight': trial.suggest_int('min_child_weight', hp['min_child_weight']['low'], \n",
    "                                                     hp['min_child_weight']['high']),\n",
    "                'subsample': trial.suggest_float('subsample', hp['subsample']['low'], hp['subsample']['high']),\n",
    "                'colsample_bytree': trial.suggest_float('colsample_bytree', hp['colsample_bytree']['low'], \n",
    "                                                        hp['colsample_bytree']['high']),\n",
    "                'learning_rate': trial.suggest_float('learning_rate', hp['learning_rate']['low'], \n",
    "                                                    hp['learning_rate']['high'], log=True)\n",
    "            }\n",
    "        \n",
    "        def ml_m_params(trial):\n",
    "            hp = create_hyperparameter_space()\n",
    "            return {\n",
    "                'n_estimators': trial.suggest_int('n_estimators', hp['n_estimators']['low'], \n",
    "                                                 hp['n_estimators']['high'], step=hp['n_estimators']['step']),\n",
    "                'max_depth': trial.suggest_int('max_depth', hp['max_depth']['low'], hp['max_depth']['high']),\n",
    "                'min_child_weight': trial.suggest_int('min_child_weight', hp['min_child_weight']['low'], \n",
    "                                                     hp['min_child_weight']['high']),\n",
    "                'subsample': trial.suggest_float('subsample', hp['subsample']['low'], hp['subsample']['high']),\n",
    "                'colsample_bytree': trial.suggest_float('colsample_bytree', hp['colsample_bytree']['low'], \n",
    "                                                        hp['colsample_bytree']['high']),\n",
    "                'learning_rate': trial.suggest_float('learning_rate', hp['learning_rate']['low'], \n",
    "                                                    hp['learning_rate']['high'], log=True)\n",
    "            }\n",
    "        \n",
    "        param_space = {'ml_g': ml_g_params, 'ml_m': ml_m_params}\n",
    "    \n",
    "    # Optimize hyperparameters\n",
    "    optuna_settings = {\n",
    "        'n_jobs_optuna': -1,\n",
    "        'show_progress_bar': True,\n",
    "        'verbosity': optuna.logging.WARNING,\n",
    "        'n_trials': n_trials\n",
    "    }\n",
    "    \n",
    "    model.tune_ml_models(ml_param_space=param_space, optuna_settings=optuna_settings)\n",
    "    \n",
    "    # Fit the model\n",
    "    model.fit()\n",
    "    \n",
    "    # Extract results\n",
    "    summary = model.summary\n",
    "    \n",
    "    return {\n",
    "        'model': model,\n",
    "        'coef': model.coef[0],\n",
    "        'se': model.se[0],\n",
    "        'ci_lower': model.confint()['2.5 %'].values[0],\n",
    "        'ci_upper': model.confint()['97.5 %'].values[0],\n",
    "        'pval': model.pval[0],\n",
    "        'n_obs': len(data),\n",
    "        'summary': summary\n",
    "    }\n",
    "\n",
    "def create_results_table(results_dict, title):\n",
    "    \"\"\"\n",
    "    Create formatted results table\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    results_dict : dict\n",
    "        Dictionary with model results\n",
    "    title : str\n",
    "        Table title\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    DataFrame : Formatted results table\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    for key, result in results_dict.items():\n",
    "        pval = result['pval']\n",
    "        pval_str = \"$< 0.0001$\" if round(pval, 4) == 0 else f\"{pval:.4f}\"\n",
    "    \n",
    "        rows.append({\n",
    "            'Model': key,\n",
    "            'Coefficient': f\"{result['coef']:.4f}\",\n",
    "            'Std. Error': f\"{result['se']:.4f}\",\n",
    "            '95\\\\% CI': f\"[{result['ci_lower']:.4f}, {result['ci_upper']:.4f}]\",\n",
    "            'p-value': pval_str,\n",
    "            'n. obs.': f\"{result['n_obs']:,}\",\n",
    "        })\n",
    "\n",
    "    \n",
    "    df = pd.DataFrame(rows)\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"{title.center(80)}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(df.to_string(index=False))\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Analysis: SomeRiskHome\n",
    "\n",
    "### 3.1 Base Models (PLR & IRM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a58082ff3af447bb0c43f56a51322aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f50b53a520ca40719b34aeefe04e6479",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0048c7974954d7db35e9460d725f099",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84f0005c92dc4a3193c75f0b4488dfb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69a349b9c01f43d995ddd6dff9585c53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "                           SomeRiskHome - Base Models                           \n",
      "================================================================================\n",
      "Model Coefficient Std. Error            95\\% CI    p-value n. obs.\n",
      "  PLR     -0.0880     0.0050 [-0.0977, -0.0782] $< 0.0001$  55,510\n",
      "  IRM     -0.0797     0.0078 [-0.0951, -0.0644] $< 0.0001$  55,510\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run base models for SomeRiskHome\n",
    "somerisk_base_plr = run_doubleml_model(data_complete, 'SomeRiskHome', base_covariates, 'plr')\n",
    "somerisk_base_irm = run_doubleml_model(data_complete, 'SomeRiskHome', base_covariates, 'irm')\n",
    "\n",
    "# Create results table\n",
    "somerisk_base_results = {\n",
    "    'PLR': somerisk_base_plr,\n",
    "    'IRM': somerisk_base_irm\n",
    "}\n",
    "\n",
    "somerisk_base_table = create_results_table(\n",
    "    somerisk_base_results, \n",
    "    \"SomeRiskHome - Base Models\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to LaTeX\n",
    "latex_base_somerisk = somerisk_base_table.to_latex(index=False, caption=\"SomeRiskHome - Base Models (PLR and IRM)\",  label=\"tab:somerisk_base\", )\n",
    "\n",
    "# Save to tables/ folder\n",
    "with open('tables/somerisk_base.tex', 'w') as f:\n",
    "    f.write(latex_base_somerisk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Extended Models (PLR & IRM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f47477788c34863aea5f32173689a30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "608c19cc2a0c40c5af2cd57202f73855",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4be8c6e2c6cd415f8e0aeb0a8874ece8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd4e5f9bde7a404eb0e753e2fe93f85c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11a3af8216b24a7e93dfc779ef17fffa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "                         SomeRiskHome - Extended Models                         \n",
      "================================================================================\n",
      "Model Coefficient Std. Error            95\\% CI    p-value n. obs.\n",
      "  PLR     -0.0866     0.0050 [-0.0964, -0.0768] $< 0.0001$  55,510\n",
      "  IRM     -0.0757     0.0075 [-0.0904, -0.0610] $< 0.0001$  55,510\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run extended models for SomeRiskHome\n",
    "somerisk_ext_plr = run_doubleml_model(data_complete, 'SomeRiskHome', extended_covariates, 'plr')\n",
    "somerisk_ext_irm = run_doubleml_model(data_complete, 'SomeRiskHome', extended_covariates, 'irm')\n",
    "\n",
    "# Create results table\n",
    "somerisk_ext_results = {\n",
    "    'PLR': somerisk_ext_plr,\n",
    "    'IRM': somerisk_ext_irm\n",
    "}\n",
    "\n",
    "somerisk_ext_table = create_results_table(\n",
    "    somerisk_ext_results, \n",
    "    \"SomeRiskHome - Extended Models\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to LaTeX\n",
    "latex_ext_somerisk = somerisk_ext_table.to_latex(index=False, caption=\"SomeRiskHome - Extended Models (PLR and IRM)\",  label=\"tab:somerisk_ext\")\n",
    "\n",
    "# Save to tables/ folder\n",
    "with open('tables/somerisk_ext.tex', 'w') as f:\n",
    "    f.write(latex_ext_somerisk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Subsample Analysis by RiskSource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "RiskSource: No risk\n",
      "============================================================\n",
      "Sample size: 23323\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce97ba1e9db543c88187321e03d0b73c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77aca0d7f14941e89cb55acd23e37393",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dcbce489d7b4e448a7e6dfcc84bbb55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0d3e64c07564ef5ba95a29ed614aa36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21b27644d454472f9bcca66175f890a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "875a52530e344b4e90014f4c93a7bf41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e564fec788e24f57807d78c309d9b719",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1aac9622600a4e9581b08f51b93585cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e92b75e0c8ac4e89ae188064b3974aa3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a6203d90b8245019f49a7bf6a49f709",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "                       SomeRiskHome - RiskSource: No risk                       \n",
      "================================================================================\n",
      "       Model Coefficient Std. Error            95\\% CI    p-value n. obs.\n",
      "    Base PLR     -0.0626     0.0101 [-0.0824, -0.0428] $< 0.0001$  23,323\n",
      "    Base IRM     -0.0656     0.0151 [-0.0951, -0.0360] $< 0.0001$  23,323\n",
      "Extended PLR     -0.0623     0.0101 [-0.0822, -0.0425] $< 0.0001$  23,323\n",
      "Extended IRM     -0.0664     0.0165 [-0.0987, -0.0342]     0.0001  23,323\n",
      "================================================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "RiskSource: Moderate to high risk\n",
      "============================================================\n",
      "Sample size: 20603\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c148c0557bc343e2938ddfdd7c292c2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92b4fa0b99c94f0b8b867d2a7e5c56d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "700e5cfe60b04892a2cf4fa8b9bb7544",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfe79852292d4d6298f2909c4c0f8c69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3035f2b2cbad44a89bd5790a41150192",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9260231f36c24704af36862575260c9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a558daeef87544788fc33291b11cf897",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "529c428ca68f4fd78e0e44e3754114ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b90f240c46a49288676c8da029487ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffc9fc356a284959a6290bd601175f9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "                SomeRiskHome - RiskSource: Moderate to high risk                \n",
      "================================================================================\n",
      "       Model Coefficient Std. Error            95\\% CI    p-value n. obs.\n",
      "    Base PLR     -0.1145     0.0074 [-0.1289, -0.1001] $< 0.0001$  20,603\n",
      "    Base IRM     -0.1012     0.0115 [-0.1238, -0.0785] $< 0.0001$  20,603\n",
      "Extended PLR     -0.1127     0.0074 [-0.1272, -0.0983] $< 0.0001$  20,603\n",
      "Extended IRM     -0.0985     0.0115 [-0.1210, -0.0759] $< 0.0001$  20,603\n",
      "================================================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "RiskSource: Very high risk\n",
      "============================================================\n",
      "Sample size: 11584\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65a9ca44368942c4ac7cf4e2f442fdfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcbdbbbca9c84c7bbd32300f6547545c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c018d5b74965475eb9f1923f2ced74ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9212c573125f4b738fde93d8f732a998",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c5de1bb641241e5a8896b942a5b04e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e359a6ecd1974c38a3ee2438c3cded6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "105b5a2812894862979ad74ce62c9c24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e27067e1cc824ea7b563e46b3071667c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a58349bff954862a2b2902f78bf9d3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46b3330af1ce4fc49dd04827c5a95a92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "                   SomeRiskHome - RiskSource: Very high risk                    \n",
      "================================================================================\n",
      "       Model Coefficient Std. Error            95\\% CI    p-value n. obs.\n",
      "    Base PLR     -0.0841     0.0069 [-0.0976, -0.0706] $< 0.0001$  11,584\n",
      "    Base IRM     -0.0688     0.0074 [-0.0834, -0.0542] $< 0.0001$  11,584\n",
      "Extended PLR     -0.0841     0.0069 [-0.0975, -0.0707] $< 0.0001$  11,584\n",
      "Extended IRM     -0.0753     0.0107 [-0.0962, -0.0544] $< 0.0001$  11,584\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Subsample analysis for SomeRiskHome\n",
    "somerisk_subsample_results = {}\n",
    "\n",
    "for risk_cat in risk_categories:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"RiskSource: {risk_cat}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Filter data for this RiskSource category\n",
    "    subsample_data = data_complete[data_complete['RiskSource'] == risk_cat].copy()\n",
    "    print(f\"Sample size: {len(subsample_data)}\")\n",
    "    \n",
    "    if len(subsample_data) < 100:\n",
    "        print(f\"Warning: Small sample size for {risk_cat}\")\n",
    "        continue\n",
    "    \n",
    "    # Run all 4 models\n",
    "    base_plr = run_doubleml_model(subsample_data, 'SomeRiskHome', base_covariates, 'plr', n_trials=50)\n",
    "    base_irm = run_doubleml_model(subsample_data, 'SomeRiskHome', base_covariates, 'irm', n_trials=50)\n",
    "    ext_plr = run_doubleml_model(subsample_data, 'SomeRiskHome', extended_covariates, 'plr', n_trials=50)\n",
    "    ext_irm = run_doubleml_model(subsample_data, 'SomeRiskHome', extended_covariates, 'irm', n_trials=50)\n",
    "    \n",
    "    somerisk_subsample_results[risk_cat] = {\n",
    "        'Base PLR': base_plr,\n",
    "        'Base IRM': base_irm,\n",
    "        'Extended PLR': ext_plr,\n",
    "        'Extended IRM': ext_irm\n",
    "    }\n",
    "    \n",
    "    # Create table for this subsample\n",
    "    subsample_table = create_results_table(\n",
    "        somerisk_subsample_results[risk_cat],\n",
    "        f\"SomeRiskHome - RiskSource: {risk_cat}\"\n",
    "    )\n",
    "    \n",
    "    # Export to LaTeX\n",
    "    latex_subsample = subsample_table.to_latex(\n",
    "        index=False, \n",
    "        caption=f\"SomeRiskHome - RiskSource: {risk_cat}\",\n",
    "        label=f\"tab:somerisk_{risk_cat.replace(' ', '_').lower()}\"\n",
    "    )\n",
    "    \n",
    "    # Save to tables/ folder\n",
    "    risk_name = risk_cat.replace(' ', '_').lower()\n",
    "    filename = f'tables/somerisk_{risk_name}.tex'\n",
    "    with open(filename, 'w') as f:\n",
    "        f.write(latex_subsample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Analysis: VeryHighRiskHome\n",
    "\n",
    "### 4.1 Base Models (PLR & IRM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d05ccd17d3249bfb85fb846086a079c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f7f5ee8afd44ecb8109ee534e84ef61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5480d5699cab46e292ef73979d3faee7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7fab61db2d14f2e91b1b5388d278fcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c6970768ed24b3181e65e33523af98c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "                         VeryHighRiskHome - Base Models                         \n",
      "================================================================================\n",
      "Model Coefficient Std. Error            95\\% CI    p-value n. obs.\n",
      "  PLR     -0.0648     0.0055 [-0.0755, -0.0541] $< 0.0001$  55,510\n",
      "  IRM     -0.0681     0.0083 [-0.0844, -0.0518] $< 0.0001$  55,510\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run base models for VeryHighRiskHome\n",
    "veryhigh_base_plr = run_doubleml_model(data_complete, 'VeryHighRiskHome', base_covariates, 'plr')\n",
    "veryhigh_base_irm = run_doubleml_model(data_complete, 'VeryHighRiskHome', base_covariates, 'irm')\n",
    "\n",
    "# Create results table\n",
    "veryhigh_base_results = {\n",
    "    'PLR': veryhigh_base_plr,\n",
    "    'IRM': veryhigh_base_irm\n",
    "}\n",
    "\n",
    "veryhigh_base_table = create_results_table(\n",
    "    veryhigh_base_results, \n",
    "    \"VeryHighRiskHome - Base Models\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to LaTeX\n",
    "latex_base_veryhigh = veryhigh_base_table.to_latex(index=False, caption=\"VeryHighRiskHome - Base Models (PLR and IRM)\", label=\"tab:veryhigh_base\")\n",
    "\n",
    "# Save to tables/ folder\n",
    "with open('tables/veryhigh_base.tex', 'w') as f:\n",
    "    f.write(latex_base_veryhigh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Extended Models (PLR & IRM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdf0432e0fbe4e13b90c87733d8b4a8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1490d586947d46749e5979d080ebd642",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1d5f860953347409cdd30f4570975c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73eb3f12633d43278c85bb66c73a98e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44a8959f650c42e1a5d2e085e3e157a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "                       VeryHighRiskHome - Extended Models                       \n",
      "================================================================================\n",
      "Model Coefficient Std. Error            95\\% CI    p-value n. obs.\n",
      "  PLR     -0.0653     0.0055 [-0.0760, -0.0545] $< 0.0001$  55,510\n",
      "  IRM     -0.0668     0.0069 [-0.0803, -0.0533] $< 0.0001$  55,510\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run extended models for VeryHighRiskHome\n",
    "veryhigh_ext_plr = run_doubleml_model(data_complete, 'VeryHighRiskHome', extended_covariates, 'plr')\n",
    "veryhigh_ext_irm = run_doubleml_model(data_complete, 'VeryHighRiskHome', extended_covariates, 'irm')\n",
    "\n",
    "# Create results table\n",
    "veryhigh_ext_results = {\n",
    "    'PLR': veryhigh_ext_plr,\n",
    "    'IRM': veryhigh_ext_irm\n",
    "}\n",
    "\n",
    "veryhigh_ext_table = create_results_table(\n",
    "    veryhigh_ext_results, \n",
    "    \"VeryHighRiskHome - Extended Models\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to LaTeX\n",
    "latex_ext_veryhigh = veryhigh_ext_table.to_latex(index=False, caption=\"VeryHighRiskHome - Extended Models (PLR and IRM)\", label=\"tab:veryhigh_ext\")\n",
    "\n",
    "# Save to tables/ folder\n",
    "with open('tables/veryhigh_ext.tex', 'w') as f:\n",
    "    f.write(latex_ext_veryhigh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Subsample Analysis by RiskSource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Subsample Analysis for VeryHighRiskHome...\n",
      "\n",
      "\n",
      "============================================================\n",
      "RiskSource: No risk\n",
      "============================================================\n",
      "Sample size: 23323\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b119d7a89fe48099e23fcc6a461ddaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "184cbddbc4864492a121316b9b9268ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa0a3df4b83c4a5f89c25fe512fe1289",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c005452bf9a46289af9f69fcb444be2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a45159eb38f14bcbb5f4d3e6a5f32caa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a093030a133147c98a358aad8453c551",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed19dc2269124cf287df516791b2cfc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2833ed28994a4c2c9196b6ded99e422d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50750e5a0262411b88ce501f6cfa4cee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b017c277c9494db996fe8011a87c3684",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "                     VeryHighRiskHome - RiskSource: No risk                     \n",
      "================================================================================\n",
      "       Model Coefficient Std. Error           95\\% CI p-value n. obs.\n",
      "    Base PLR     -0.0034     0.0063 [-0.0158, 0.0090]  0.5919  23,323\n",
      "    Base IRM      0.0178     0.0142 [-0.0100, 0.0456]  0.2104  23,323\n",
      "Extended PLR     -0.0043     0.0063 [-0.0167, 0.0081]  0.4993  23,323\n",
      "Extended IRM     -0.0049     0.0118 [-0.0281, 0.0183]  0.6768  23,323\n",
      "================================================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "RiskSource: Moderate to high risk\n",
      "============================================================\n",
      "Sample size: 20603\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09590a18821744b8a498e288b8202354",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ae9334bd4ef49cf8460267e0bf1a777",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fff0f951b4a44c9a554d041dfa99d0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9aec1069d1e74dadacba0e2bfa28f395",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "682bdd8afc854c96b8b13f3b2e9dcc00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8c9fb18832a4f6ca7c21744ee076077",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33c0899bcdf24fa39be5fa5fd072371d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2add16ac30a14e3ca116087c675087e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abfcdebbfe4148659bc47e050e4715b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a388a3749fd142cba745030ee0afdf06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "              VeryHighRiskHome - RiskSource: Moderate to high risk              \n",
      "================================================================================\n",
      "       Model Coefficient Std. Error            95\\% CI    p-value n. obs.\n",
      "    Base PLR     -0.0382     0.0086 [-0.0551, -0.0214] $< 0.0001$  20,603\n",
      "    Base IRM     -0.0481     0.0137 [-0.0749, -0.0212]     0.0005  20,603\n",
      "Extended PLR     -0.0374     0.0087 [-0.0544, -0.0205] $< 0.0001$  20,603\n",
      "Extended IRM     -0.0441     0.0138 [-0.0712, -0.0170]     0.0014  20,603\n",
      "================================================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "RiskSource: Very high risk\n",
      "============================================================\n",
      "Sample size: 11584\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0b284c6e34d49abac3d652347ad9fe6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbeafc1a49b74e87bc6e35f95696591f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d76783b4a104128a7c1af9d7c720501",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "952eced5426842eca57d47b09d333471",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7effe25f7f1345fcac00dd4b3037c62d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "770c1c087ca0470db66191e68cbc2361",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a49579cb51b84644b00f2df18cdb7b46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6832d1d5af09448a854e09fed4116d49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fc67d9fa6014317924a0f41aee9e18b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e508702784384c7b8a9202f865674296",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "                 VeryHighRiskHome - RiskSource: Very high risk                  \n",
      "================================================================================\n",
      "       Model Coefficient Std. Error            95\\% CI    p-value n. obs.\n",
      "    Base PLR     -0.2065     0.0129 [-0.2318, -0.1811] $< 0.0001$  11,584\n",
      "    Base IRM     -0.2223     0.0196 [-0.2608, -0.1839] $< 0.0001$  11,584\n",
      "Extended PLR     -0.2071     0.0130 [-0.2325, -0.1817] $< 0.0001$  11,584\n",
      "Extended IRM     -0.2139     0.0192 [-0.2515, -0.1763] $< 0.0001$  11,584\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Subsample analysis for VeryHighRiskHome\n",
    "print(\"Running Subsample Analysis for VeryHighRiskHome...\\n\")\n",
    "\n",
    "veryhigh_subsample_results = {}\n",
    "\n",
    "for risk_cat in risk_categories:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"RiskSource: {risk_cat}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Filter data for this RiskSource category\n",
    "    subsample_data = data_complete[data_complete['RiskSource'] == risk_cat].copy()\n",
    "    print(f\"Sample size: {len(subsample_data)}\")\n",
    "    \n",
    "    if len(subsample_data) < 100:\n",
    "        print(f\"Warning: Small sample size for {risk_cat}\")\n",
    "        continue\n",
    "    \n",
    "    # Run all 4 models\n",
    "    base_plr = run_doubleml_model(subsample_data, 'VeryHighRiskHome', base_covariates, 'plr', n_trials=50)\n",
    "    base_irm = run_doubleml_model(subsample_data, 'VeryHighRiskHome', base_covariates, 'irm', n_trials=50)\n",
    "    ext_plr = run_doubleml_model(subsample_data, 'VeryHighRiskHome', extended_covariates, 'plr', n_trials=50)\n",
    "    ext_irm = run_doubleml_model(subsample_data, 'VeryHighRiskHome', extended_covariates, 'irm', n_trials=50)\n",
    "    \n",
    "    veryhigh_subsample_results[risk_cat] = {\n",
    "        'Base PLR': base_plr,\n",
    "        'Base IRM': base_irm,\n",
    "        'Extended PLR': ext_plr,\n",
    "        'Extended IRM': ext_irm\n",
    "    }\n",
    "    \n",
    "    # Create table for this subsample\n",
    "    subsample_table = create_results_table(\n",
    "        veryhigh_subsample_results[risk_cat],\n",
    "        f\"VeryHighRiskHome - RiskSource: {risk_cat}\"\n",
    "    )\n",
    "    \n",
    "    # Export to LaTeX\n",
    "    latex_subsample = subsample_table.to_latex(\n",
    "        index=False, \n",
    "        caption=f\"VeryHighRiskHome - RiskSource: {risk_cat}\",\n",
    "        label=f\"tab:veryhigh_{risk_cat.replace(' ', '_').lower()}\"\n",
    "    )\n",
    "    \n",
    "    # Save to tables/ folder\n",
    "    risk_name = risk_cat.replace(' ', '_').lower()\n",
    "    filename = f'tables/veryhigh_{risk_name}.tex'\n",
    "    with open(filename, 'w') as f:\n",
    "        f.write(latex_subsample)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## 5. Multi-Learner Comparison and Robustness Analysis\n\nFollowing best practices in empirical DML research (Chernozhukov et al., 2018; Ahrens et al., 2024), we compare multiple machine learning algorithms to demonstrate robustness of our estimates. This section:\n\n1. **Compares multiple learners**: Lasso, Random Forest, XGBoost, and mixed combinations\n2. **Reports nuisance model performance**: RMSE for outcome (ml_l/ml_g) and treatment (ml_m) models\n3. **Tests learner mixing**: Different optimal learners for outcome vs. treatment prediction\n4. **Uses consistent sample splitting**: All models use the same cross-validation folds for fair comparison\n\nThis approach validates DML's \"machine learning agnostic\" property and avoids cherry-picking a single model.",
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}